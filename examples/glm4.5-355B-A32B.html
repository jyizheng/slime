
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Training GLM-4.5 with 64xH100 &#8212; slime</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom_log.css?v=731335ad" />
    <link rel="stylesheet" type="text/css" href="../_static/css/custom_log.css?v=731335ad" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=e645c8fa"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=ccdb6887"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'examples/glm4.5-355B-A32B';</script>
    <link rel="icon" href="../_static/logo.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="GLM4-9B" href="glm4-9B.html" />
    <link rel="prev" title="Training DeepSeek R1 with 128xH100" href="deepseek-r1.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
    <meta name="docbuild:last-update" content="Sep 04, 2025"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.jpg" class="logo__image only-light" alt="slime - Home"/>
    <script>document.write(`<img src="../_static/logo.jpg" class="logo__image only-dark" alt="slime - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Get Started</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../get_started/quick_start.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../get_started/usage.html">Usage Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../get_started/qa.html">FAQ</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Examples</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="qwen3-4b-base-openhermes.html">Qwen3-4B-Base with OpenHermes-2.5</a></li>
<li class="toctree-l1"><a class="reference internal" href="deepseek-r1.html">Training DeepSeek R1 with 128xH100</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Training GLM-4.5 with 64xH100</a></li>
<li class="toctree-l1"><a class="reference internal" href="glm4-9B.html">GLM4-9B</a></li>
<li class="toctree-l1"><a class="reference internal" href="qwen3-4B.html">Qwen3-4B</a></li>
<li class="toctree-l1"><a class="reference internal" href="qwen3-30B-A3B.html">Training Qwen3-30B-A3B with 8xH100</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Advanced Features</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../advanced/speculative-decoding.html">Speculative Decoding – Usage Guide</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Developer Guide</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../developer_guide/debug.html">Debugging</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Hardware Platforms</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../platform_support/amd_tutorial.html">AMD</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/sgl-project/sgl-project.github.io" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/sgl-project/sgl-project.github.io/blob/main/examples/glm4.5-355B-A32B.md?plain=1" target="_blank"
   class="btn btn-sm btn-source-file-button dropdown-item"
   title="Show source"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-code"></i>
  </span>
<span class="btn__text-container">Show source</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/sgl-project/sgl-project.github.io/edit/main/examples/glm4.5-355B-A32B.md" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/sgl-project/sgl-project.github.io/issues/new?title=Issue%20on%20page%20%2Fexamples/glm4.5-355B-A32B.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/examples/glm4.5-355B-A32B.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Training GLM-4.5 with 64xH100</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#environment-setup">Environment Setup</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#executing-the-training">Executing the Training</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#parameter-introduction">Parameter Introduction</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#perf-args">PERF_ARGS</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#grpo-args">GRPO_ARGS</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#optimizer-args">OPTIMIZER_ARGS</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#sglang-args">SGLANG_ARGS</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#misc-args">MISC_ARGS</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fp8-rollout">FP8 Rollout</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="training-glm-4-5-with-64xh100">
<h1>Training GLM-4.5 with 64xH100<a class="headerlink" href="#training-glm-4-5-with-64xh100" title="Link to this heading">#</a></h1>
<p>This is an example of doing GLM-4.5 RL training using 64xH100 GPUs.</p>
<section id="environment-setup">
<h2>Environment Setup<a class="headerlink" href="#environment-setup" title="Link to this heading">#</a></h2>
<p>For instructions on setting up the environment and downloading data, please refer to <a class="reference internal" href="qwen3-4B.html"><span class="std std-doc">Example: Qwen3-4B</span></a>.</p>
<p>First, you will need to download GLM-4.5 to a directory accessible by all machines (hereinafter referred to as <code class="docutils literal notranslate"><span class="pre">$BASE_DIR</span></code>):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>huggingface-cli<span class="w"> </span>download<span class="w"> </span>zai-org/GLM-4.5<span class="w"> </span>--local-dir<span class="w"> </span><span class="nv">$BASE_DIR</span>/GLM-4.5-355B-A32B
</pre></div>
</div>
<p>Next, we need to convert the huggingface checkpoint into the torch_dist format with 2 nodes, each with 8 GPUs:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>slime/
<span class="nb">source</span><span class="w"> </span>scripts/models/glm4.5-355B-A32B.sh
<span class="nv">PYTHONPATH</span><span class="o">=</span>/root/Megatron-LM/<span class="w"> </span>torchrun<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--nproc-per-node<span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--master-addr<span class="w"> </span><span class="si">${</span><span class="nv">MASTER_ADDR</span><span class="si">}</span><span class="w"> </span>--master-port<span class="w"> </span><span class="m">12345</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--nnodes<span class="o">=</span><span class="m">2</span><span class="w"> </span>--node-rank<span class="w"> </span><span class="si">${</span><span class="nv">NODE_RANK</span><span class="si">}</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>tools/convert_hf_to_torch_dist.py<span class="w"> </span><span class="se">\</span>
<span class="w">   </span><span class="si">${</span><span class="nv">MODEL_ARGS</span><span class="p">[@]</span><span class="si">}</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--hf-checkpoint<span class="w"> </span><span class="nv">$BASE_DIR</span>/GLM-4.5-355B-A32B/<span class="w"> </span><span class="se">\</span>
<span class="w">   </span>--save<span class="w"> </span><span class="nv">$BASE_DIR</span>/GLM-4.5-355B-A32B_torch_dist/
</pre></div>
</div>
<p>Here, <code class="docutils literal notranslate"><span class="pre">MASTER_ADDR</span></code> is the IP of node0, and <code class="docutils literal notranslate"><span class="pre">NODE_RANK</span></code> indicates the node’s index, both configured similarly to a multi-node <code class="docutils literal notranslate"><span class="pre">torchrun</span></code> setup.</p>
</section>
<section id="executing-the-training">
<h2>Executing the Training<a class="headerlink" href="#executing-the-training" title="Link to this heading">#</a></h2>
<p>On node0, run:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>slime/
bash<span class="w"> </span>scripts/run-glm4.5-355B-A32B.sh
</pre></div>
</div>
<p>On other nodes, you need to join the Ray cluster with the following command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>ray<span class="w"> </span>start<span class="w"> </span>--address<span class="o">=</span><span class="si">${</span><span class="nv">MASTER_ADDR</span><span class="si">}</span>:6379<span class="w"> </span>--num-gpus<span class="w"> </span><span class="m">8</span><span class="w"> </span>--node-ip-address<span class="w"> </span><span class="si">${</span><span class="nv">WORKER_IP</span><span class="si">}</span><span class="w"> </span>--disable-usage-stats<span class="s2">&quot;</span>
</pre></div>
</div>
<p>Alternatively, if you have a list of all node IPs, for example, an MPI hostfile (where each line is <code class="docutils literal notranslate"><span class="pre">ip</span> <span class="pre">slot=8</span></code>), you can add the following commands after the <code class="docutils literal notranslate"><span class="pre">ray</span> <span class="pre">start</span> <span class="pre">--head</span></code> command in <code class="docutils literal notranslate"><span class="pre">scripts/run-glm4.5-355B-A32B.sh.sh</span></code>. This allows you to execute the training entirely from node0:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="k">for</span><span class="w"> </span>WORKER_IP<span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="k">$(</span>awk<span class="w"> </span><span class="s1">&#39;{print $1}&#39;</span><span class="w"> </span><span class="nv">$BASE_DIR</span>/mpi_hostfile<span class="k">)</span><span class="p">;</span><span class="w"> </span><span class="k">do</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="o">[[</span><span class="w"> </span><span class="s2">&quot;</span><span class="nv">$WORKER_IP</span><span class="s2">&quot;</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s2">&quot;</span><span class="nv">$MASTER_ADDR</span><span class="s2">&quot;</span><span class="w"> </span><span class="o">]]</span><span class="p">;</span><span class="w"> </span><span class="k">then</span>
<span class="w">    </span><span class="k">continue</span>
<span class="w">  </span><span class="k">fi</span>
<span class="w">  </span><span class="nb">echo</span><span class="w"> </span><span class="s2">&quot;Starting Ray worker on </span><span class="si">${</span><span class="nv">WORKER_IP</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="w">  </span>ssh<span class="w"> </span>root@<span class="s2">&quot;</span><span class="si">${</span><span class="nv">WORKER_IP</span><span class="si">}</span><span class="s2">&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span><span class="s2">&quot;pkill -9 sglang ; ray stop --force ; pkill -9 python ; ray start --address=</span><span class="si">${</span><span class="nv">MASTER_ADDR</span><span class="si">}</span><span class="s2">:6379 --num-gpus 8 --node-ip-address </span><span class="si">${</span><span class="nv">WORKER_IP</span><span class="si">}</span><span class="s2"> --disable-usage-stats&quot;</span><span class="w"> </span><span class="p">&amp;</span>
<span class="k">done</span>
<span class="nb">wait</span>
</pre></div>
</div>
<section id="parameter-introduction">
<h3>Parameter Introduction<a class="headerlink" href="#parameter-introduction" title="Link to this heading">#</a></h3>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">SCRIPT_DIR</span><span class="o">=</span><span class="s2">&quot;</span><span class="k">$(</span><span class="nb">cd</span><span class="w"> </span>--<span class="w"> </span><span class="s2">&quot;</span><span class="k">$(</span>dirname<span class="w"> </span>--<span class="w"> </span><span class="s2">&quot;</span><span class="si">${</span><span class="nv">BASH_SOURCE</span><span class="p">[0]</span><span class="si">}</span><span class="s2">&quot;</span><span class="k">)</span><span class="s2">&quot;</span><span class="w"> </span><span class="p">&amp;</span>&gt;/dev/null<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="nb">pwd</span><span class="k">)</span><span class="s2">&quot;</span>
<span class="nb">source</span><span class="w"> </span><span class="s2">&quot;</span><span class="si">${</span><span class="nv">SCRIPT_DIR</span><span class="si">}</span><span class="s2">/models/glm4.5-355B-A32B.sh&quot;</span>
</pre></div>
</div>
<p>This reads the model’s config from <a class="reference download internal" download="" href="../_downloads/ed4073202c599ef76c7cb933d6aa14c3/glm4.5-355B-A32B.sh"><span class="xref download myst">scripts/models/glm4.5-355B-A32B.sh</span></a>. These configs are all Megatron parameters. When training with Megatron, it cannot read the model config from the checkpoint, so we need to configure it ourselves. We provide some examples in <a class="reference internal" href="#../../../scripts/models/"><span class="xref myst">scripts/models</span></a>.</p>
<section id="perf-args">
<h4>PERF_ARGS<a class="headerlink" href="#perf-args" title="Link to this heading">#</a></h4>
<p>A set of Megatron parallelism parameters. Only <code class="docutils literal notranslate"><span class="pre">--use-dynamic-batch-size</span></code> and <code class="docutils literal notranslate"><span class="pre">--max-tokens-per-gpu</span></code> are added by slime.</p>
<p>For the Megatron part, we have configured TP8, PP4, CP2, and EP16.</p>
<p><code class="docutils literal notranslate"><span class="pre">max_tokens_per_gpu</span></code> refers to the maximum number of tokens each GPU can process. When <code class="docutils literal notranslate"><span class="pre">use_dynamic_batch_size</span></code> is enabled, it will pack data of varying lengths within a batch as close to <code class="docutils literal notranslate"><span class="pre">max_tokens_per_gpu</span></code>. If a single data item exceeds <code class="docutils literal notranslate"><span class="pre">max_tokens_per_gpu</span></code>, it will form its own batch without truncation. When context parallelism (CP) is enabled, it allows CP GPUs to share a total length of <code class="docutils literal notranslate"><span class="pre">CP</span> <span class="pre">*</span> <span class="pre">max_tokens_per_gpu</span></code> tokens.</p>
<p>When <code class="docutils literal notranslate"><span class="pre">dynamic_batch_size</span></code> is enabled, the traditional <code class="docutils literal notranslate"><span class="pre">micro_batch_size</span></code> is ignored.</p>
<p>⚠️ slime always trains the model using data packing and strictly guarantees per-sample or per-token loss. This means enabling dynamic batch size will not affect the loss calculation. It is recommended to enable it.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">PERF_ARGS</span><span class="o">=(</span>
<span class="w">   </span>--tensor-model-parallel-size<span class="w"> </span><span class="m">8</span>
<span class="w">   </span>--sequence-parallel
<span class="w">   </span>--pipeline-model-parallel-size<span class="w"> </span><span class="m">4</span>
<span class="w">   </span>--context-parallel-size<span class="w"> </span><span class="m">2</span>
<span class="w">   </span>--expert-model-parallel-size<span class="w"> </span><span class="m">16</span>
<span class="w">   </span>--expert-tensor-parallel-size<span class="w"> </span><span class="m">1</span>

<span class="w">   </span>--recompute-granularity<span class="w"> </span>full
<span class="w">   </span>--recompute-method<span class="w"> </span>uniform
<span class="w">   </span>--recompute-num-layers<span class="w"> </span><span class="m">1</span>

<span class="w">   </span>--use-dynamic-batch-size
<span class="w">   </span>--max-tokens-per-gpu<span class="w"> </span><span class="m">16384</span>
<span class="o">)</span>
</pre></div>
</div>
</section>
<section id="grpo-args">
<h4>GRPO_ARGS<a class="headerlink" href="#grpo-args" title="Link to this heading">#</a></h4>
<p>Currently, these are some GRPO-related parameters in slime:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">GRPO_ARGS</span><span class="o">=(</span>
<span class="w">   </span>--advantage-estimator<span class="w"> </span>grpo
<span class="w">   </span>--use-kl-loss
<span class="w">   </span>--kl-loss-coef<span class="w"> </span><span class="m">0</span>.00
<span class="w">   </span>--kl-loss-type<span class="w"> </span>low_var_kl
<span class="w">   </span>--entropy-coef<span class="w"> </span><span class="m">0</span>.00
<span class="w">   </span>--eps-clip<span class="w"> </span><span class="m">0</span>.2
<span class="w">   </span>--eps-clip-high<span class="w"> </span><span class="m">0</span>.28
<span class="o">)</span>
</pre></div>
</div>
<p>If you wish to train without loading the reference model, you need to remove <code class="docutils literal notranslate"><span class="pre">--use-kl-loss</span></code> and set <code class="docutils literal notranslate"><span class="pre">--kl-coef</span> <span class="pre">0.00</span></code> (the default value is 0).</p>
</section>
<section id="optimizer-args">
<h4>OPTIMIZER_ARGS<a class="headerlink" href="#optimizer-args" title="Link to this heading">#</a></h4>
<p>We have configured CPU Adam with the following parameters to save GPU memory.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">OPTIMIZER_ARGS</span><span class="o">=(</span>
<span class="w">   </span>...

<span class="w">   </span>--optimizer-cpu-offload
<span class="w">   </span>--overlap-cpu-optimizer-d2h-h2d
<span class="w">   </span>--use-precision-aware-optimizer
<span class="o">)</span>
</pre></div>
</div>
</section>
<section id="sglang-args">
<h4>SGLANG_ARGS<a class="headerlink" href="#sglang-args" title="Link to this heading">#</a></h4>
<p>These are the parameters required by sglang. Here, <code class="docutils literal notranslate"><span class="pre">--rollout-num-gpus-per-engine</span></code> basically corresponds to sglang’s <code class="docutils literal notranslate"><span class="pre">tp_size</span></code>. Other sglang parameters are passed to slime by adding a <code class="docutils literal notranslate"><span class="pre">--sglang-</span></code> prefix.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">SGLANG_ARGS</span><span class="o">=(</span>
<span class="w">   </span>--rollout-num-gpus-per-engine<span class="w"> </span><span class="m">32</span>
<span class="w">   </span>--sglang-mem-fraction-static<span class="w"> </span><span class="m">0</span>.7
<span class="w">   </span>--sglang-enable-dp-attention
<span class="w">   </span>--sglang-dp-size<span class="w"> </span><span class="m">4</span>
<span class="o">)</span>
</pre></div>
</div>
</section>
<section id="misc-args">
<h4>MISC_ARGS<a class="headerlink" href="#misc-args" title="Link to this heading">#</a></h4>
<p>Some additional Megatron configurations. Note that Megatron’s deepep is configured here.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">MISC_ARGS</span><span class="o">=(</span>
<span class="w">   </span>...

<span class="w">   </span><span class="c1"># use deepep for megatron</span>
<span class="w">   </span>--moe-enable-deepep
<span class="w">   </span>--moe-token-dispatcher-type<span class="w"> </span>flex
<span class="o">)</span>
</pre></div>
</div>
</section>
</section>
</section>
<section id="fp8-rollout">
<h2>FP8 Rollout<a class="headerlink" href="#fp8-rollout" title="Link to this heading">#</a></h2>
<p>The open-source FP8 checkpoint of GLM-4.5 is of per-channel quantization, which could not enable deepep in SGLang. We can use the tool scripts within slime to convert an FP8 checkpoint of 128x128 per-block quant:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python<span class="w"> </span>tools/convert_hf_to_fp8.py<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model-dir<span class="w"> </span><span class="nv">$BASE_DIR</span>/GLM-4.5-355B-A32B/<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--save-dir<span class="w"> </span><span class="nv">$BASE_DIR</span>/GLM-4.5-355B-A32B-FP8/<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--strategy<span class="w"> </span>block<span class="w"> </span>--block-size<span class="w"> </span><span class="m">128</span><span class="w"> </span><span class="m">128</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--max-workers<span class="w"> </span><span class="m">4</span>
</pre></div>
</div>
<p>Then, simply change <code class="docutils literal notranslate"><span class="pre">--hf-checkpoint</span></code> to <code class="docutils literal notranslate"><span class="pre">$BASE_DIR/GLM-4.5-355B-A32B-FP8/</span></code> to enable FP8 rollout.</p>
<p>And exemplar <code class="docutils literal notranslate"><span class="pre">SGLANG_ARGS</span></code> for FP8 is:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">SGLANG_ARGS</span><span class="o">=(</span>
<span class="w">   </span>--rollout-num-gpus-per-engine<span class="w"> </span><span class="m">32</span>
<span class="w">   </span>--sglang-mem-fraction-static<span class="w"> </span><span class="m">0</span>.7
<span class="w">   </span>--sglang-enable-dp-attention
<span class="w">   </span>--sglang-dp-size<span class="w"> </span><span class="m">32</span>
<span class="w">   </span>--sglang-ep-size<span class="w"> </span><span class="m">32</span>
<span class="w">   </span>--sglang-moe-dense-tp-size<span class="w"> </span><span class="m">1</span>
<span class="w">   </span>--sglang-enable-dp-lm-head
<span class="w">   </span>--sglang-cuda-graph-bs<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">2</span><span class="w"> </span><span class="m">4</span><span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="k">$(</span>seq<span class="w"> </span><span class="m">16</span><span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="m">128</span><span class="k">)</span>
<span class="w">   </span>--sglang-disable-radix-cache

<span class="w">   </span>--sglang-moe-a2a-backend<span class="w"> </span>deepep
<span class="w">   </span>--sglang-deepep-mode<span class="w"> </span>auto
<span class="o">)</span>
</pre></div>
</div>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="deepseek-r1.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Training DeepSeek R1 with 128xH100</p>
      </div>
    </a>
    <a class="right-next"
       href="glm4-9B.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">GLM4-9B</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#environment-setup">Environment Setup</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#executing-the-training">Executing the Training</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#parameter-introduction">Parameter Introduction</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#perf-args">PERF_ARGS</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#grpo-args">GRPO_ARGS</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#optimizer-args">OPTIMIZER_ARGS</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#sglang-args">SGLANG_ARGS</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#misc-args">MISC_ARGS</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fp8-rollout">FP8 Rollout</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By slime Team
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2025-2025, slime.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    <p class="last-updated">
  Last updated on Sep 04, 2025.
  <br/>
</p>
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>